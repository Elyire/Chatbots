
from itertools import zip_longest
import streamlit as st
from langchain_openai.chat_models import ChatOpenAI
from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)


# Side bar
with st.sidebar:
   
    api_key_input = st.text_input(
    "OpenAI API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”", 
    key="chatbot_api_key", 
    type="password",
    value=st.session_state.get("OPENAI_API_KEY", "YOUR_TEMP_API_KEY"),
    )

    ":green[OpenAI API Keyê°€ ì—†ìœ¼ì‹œë‹¤ë©´, [**ì±—GPTì˜ ê°œë°œì‚¬ì¸ OpenAIì˜ í™ˆí˜ì´ì§€**](https://platform.openai.com/account/api-keys)ì—ì„œ ë°œê¸‰ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.]"

    st.write("---")
    st.caption('ì˜¤ë¥¸ìª½ ìƒë‹¨ Xë¥¼ ëˆ„ë¥´ë©´ ì‚¬ì´ë“œë°”ê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤')



st.title("simple chatbot")


# Initialize session state variables
if 'generated' not in st.session_state:
    st.session_state['generated'] = []  # Store AI generated responses

if 'past' not in st.session_state:
    st.session_state['past'] = []  # Store past user inputs



# TRY EXCEPT FOR KEY VALIDATION
try:
    # Initialize the ChatOpenAI model
    chat = ChatOpenAI(
        openai_api_key=api_key_input,
        model_name="gpt-4o",
        temperature=0,
        max_tokens=4000,
    )


    def build_message_list():
        """
        Build a list of messages including system, human and AI messages.
        """
        # Start zipped_messages with the SystemMessage
        zipped_messages = [SystemMessage(
            content="""
            You are a helpful assistant.
            """)]

        # Zip together the past and generated messages
        for human_msg, ai_msg in zip_longest(st.session_state['past'], st.session_state['generated']):
            if human_msg is not None:
                zipped_messages.append(HumanMessage(
                    content=human_msg))  # Add user messages
            if ai_msg is not None:
                zipped_messages.append(
                    AIMessage(content=ai_msg))  # Add AI messages

        return zipped_messages


    def generate_response():
        """
        Generate AI response using the ChatOpenAI model.
        """
        # Build the list of messages
        zipped_messages = build_message_list()

        # Generate response using the chat model
        ai_response = chat(zipped_messages)

        return ai_response.content




    if not api_key_input or api_key_input == "YOUR_TEMP_API_KEY":
        st.error("**ê³„ì† ì§„í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” ğŸ‘ˆì‚¬ì´ë“œë°”ì— OpenAI API keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”**")
        st.stop()


    entered_prompt = st.chat_input('ë©”ì‹œì§€ ì…ë ¥', key='prompt_input')


    with st.spinner('ëŒ€í™” ìƒì„± ì¤‘..â³'):
        if entered_prompt:        
            # Get user query
            user_query = entered_prompt
            # Append user query to past queries
            st.session_state.past.append(user_query)
            # Generate response
            output = generate_response()
            # Append AI response to generated responses
            st.session_state.generated.append(output)


    #Display the chat history
    if st.session_state['generated']:
        for human_msg, ai_msg in zip(st.session_state['past'], st.session_state['generated']):
            with st.chat_message("user"):
                st.markdown(f"**You:** {human_msg}", unsafe_allow_html=True)
            with st.chat_message("ai"):
                st.markdown(f"**Assistant:** {ai_msg}", unsafe_allow_html=True)

except:
    st.error("ìœ íš¨í•œ API KEYë¥¼ ë„£ì–´ì£¼ì„¸ìš”")


